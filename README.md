# OpenWeatherAPI Data Pipeline | Data Engineering Project

T·∫≠p trung v√†o vi·ªác h·ªçc c√°ch k·∫øt n·ªëi m·ªôt s·ªë c√°c c√¥ng ngh·ªá DE ph·ªï bi·∫øn ƒë·ªÉ l√†m vi·ªác v·ªõi nhau trong Docker, kh√¥ng transform d·ªØ li·ªáu qu√° ph·ª©c t·∫°p hay ƒëi s√¢u v√†o t·ªëi ∆∞u, setup ph·ª©c t·∫°p nh∆∞ production.

---

## üìë M·ª•c l·ª•c
- [üéØ Gi·ªõi thi·ªáu](#-gi·ªõi-thi·ªáu)
- [üß© Ki·∫øn tr√∫c h·ªá th·ªëng](#-ki·∫øn-tr√∫c-h·ªá-th·ªëng)
- [üìà Lu·ªìng d·ªØ li·ªáu](#-lu·ªìng-d·ªØ-li·ªáu)
- [‚öôÔ∏è H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t & ch·∫°y](#Ô∏è-h∆∞·ªõng-d·∫´n-c√†i-ƒë·∫∑t--ch·∫°y)
- [üîó Giao di·ªán qu·∫£n tr·ªã](#-url-truy-c·∫≠p)

---

## üéØ Gi·ªõi thi·ªáu

Project n√†y ƒë√≥ng vai tr√≤ nh∆∞ m·ªôt project to√†n di·ªán ƒë·ªÉ x√¢y d·ª±ng m·ªôt pipeline d·ªØ li·ªáu end-to-end.  
Bao g·ªìm to√†n b·ªô c√°c b∆∞·ªõc t·ª´ **thu th·∫≠p d·ªØ li·ªáu th·ªùi ti·∫øt th·ª±c t·∫ø ƒë∆∞·ª£c fetching t·ª´ OpenWeather API b·ªüi Kafka**, ƒë·∫øn **x·ª≠ l√Ω d·ªØ li·ªáu v·ªõi Spark**, v√† cu·ªëi c√πng l√† **l∆∞u tr·ªØ k·∫øt qu·∫£ v√†o PostgreSQL**. T·∫•t c·∫£ lu·ªìng d·ªØ li·ªáu ƒë√≥ ƒë·ªÅu ƒë∆∞·ª£c **trigger theo l·ªãch tr√¨nh t·ª± ƒë·ªông b·ªüi Airflow** ‚Üí ƒë√¢y l√† m·ªôt b√†i to√°n **batch processing** ƒëi·ªÉn h√¨nh, n∆°i d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√Ω theo t·ª´ng l√¥ ƒë·ªãnh k·ª≥ thay v√¨ realtime.

Pipeline s·ª≠ d·ª•ng m·ªôt b·ªô c√¥ng ngh·ªá hi·ªán ƒë·∫°i bao g·ªìm **Apache Airflow, Python, Apache Kafka, Apache Spark v√† PostgreSQL**.  
To√†n b·ªô h·ªá th·ªëng ƒë∆∞·ª£c **container h√≥a b·∫±ng Docker** ƒë·ªÉ gi√∫p vi·ªác tri·ªÉn khai tr·ªü n√™n d·ªÖ d√†ng, ƒë·ªìng nh·∫•t v√† c√≥ th·ªÉ m·ªü r·ªông.

---

## üß© Ki·∫øn tr√∫c h·ªá th·ªëng
![System Architecture](Ki·∫øn tr√∫c h·ªá th·ªëng.png)
Data source: S·ª≠ d·ª•ng API t·ª´ OpenWeatherAPI ƒë·ªÉ l·∫•y d·ªØ li·ªáu v·ªÅ th·ªùi ti·∫øt ·ªü th·ªùi ƒëi·ªÉm hi·ªán t·∫°i, d·ªØ li·ªáu l·∫•y t·ª´ 3 th√†nh ph·ªë: H·∫£i Ph√≤ng, H√† N·ªôi v√† Th√†nh ph·ªë H·ªì Ch√≠ Minh
Apache Airflow: ƒê·∫£m nhi·ªám qu√° tr√¨nh ƒëi·ªÅu ph·ªëi to√†n b·ªô pipeline (bao g·ªìm trigger Kafka fetch API, submit Spark job v√† ƒë·∫©y d·ªØ li·ªáu v√†o Postgres)
Apache Kafka: message broker ƒë·ªÉ truy·ªÅn d·ªØ li·ªáu, s·ª≠ d·ª•ng KRaft mode - l∆∞u tr·ªØ v√† ph√¢n ph·ªëi message, t·ª± qu·∫£n l√≠ metadata c·ªßa ch√≠nh n√≥, lo·∫°i b·ªè s·ª± ph·ª• thu·ªôc v√†o Zookeeper
Apache Spark: Spark Cluster ch·ªãu tr√°ch nhi·ªám x·ª≠ l√Ω d·ªØ li·ªáu, trong ƒë√≥ Master node ƒëi·ªÅu ph·ªëi c√¥ng vi·ªác c√≤n Worker node th·ª±c hi·ªán x·ª≠ l√Ω v√† ghi k·∫øt qu·∫£ v√†o PostgreSQL
PostgreSQL: Qu·∫£n l√≠ metdata c·ªßa Airflow v√† n∆°i l∆∞u tr·ªØ d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√≠ t·ª´ Spark


---


## üìà Lu·ªìng d·ªØ li·ªáu
1. **Airflow** trigger DAG ƒë·ªãnh k·ª≥ ‚Üí g·ªçi Python script.  
2. Script g·ªçi **OpenWeather API** ‚Üí l·∫•y d·ªØ li·ªáu 3 th√†nh ph·ªë ‚Üí g·ª≠i v√†o **Kafka topic `weather-data`**.  
3. **Spark job** (submit s·ª≠ d·ª•ng `SparkSubmitOperator`) ƒë·ªçc t·ª´ Kafka ‚Üí x·ª≠ l√Ω d·ªØ li·ªáu:  
   - Chu·∫©n h√≥a schema  
   - Ph√¢n lo·∫°i m·ª©c nhi·ªát ƒë·ªô (l·∫°nh / m√°t / n√≥ng)  
4. Spark ghi d·ªØ li·ªáu v√†o b·∫£ng PostgreSQL `weather_processed`.  
5. C√≥ th·ªÉ xem d·ªØ li·ªáu qua **pgAdmin UI** ho·∫∑c ch·∫°y **SQL query**.  


---

## ‚öôÔ∏è H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t & ch·∫°y

1. Clone repository:
    ```bash
    git clone 
    ```
2. V√†o https://openweathermap.org/api l·∫•y API KEY, sau ƒë√≥ t·∫°o file .env v√† g√°n:
    ```bash
    OPENWEATHER_API_KEY=
    ```
3. G√°n th√™m bi·∫øn sau v√†o .env
    ```bash
    AIRFLOW_UID=50000
    ```
4. M·∫∑c ƒë·ªãnh image c·ªßa apache/airflow:3.0.6 kh√¥ng bao g·ªìm Java Runtime. M√† ta l·∫°i d√πng SparkSubmitOperator ·ªü deploy mode l√† client ƒë·ªÉ submit job cho Spark Cluster (·ªü ƒë√¢y l√† t·ª´ image apache:spark), n√™n y√™u c·∫ßu Java c√≥ s·∫µn trong m√¥i tr∆∞·ªùng, ƒë·ªìng th·ªùi c√†i m·ªôt s·ªë Python package c·∫ßn thi·∫øt. Ch√≠nh v√¨ th·∫ø ta c·∫ßn ph·∫£i build l·∫°i custom Airflow image:
    ```bash
    docker compose build
    ```
5. Kh·ªüi ƒë·ªông database:
    ```bash
    docker compose up airflow-init
    ```
6. Kh·ªüi ƒë·ªông t·∫•t c·∫£ c√°c service:
    ```bash
    docker compose up -d
    ```
7. V√†o Airflow Web Server http://localhost:8082/, ƒëƒÉng nh·∫≠p v·ªõi login/password l√† airflow/airflow, sau ƒë√≥ ch·ªçn Admin -> Connections -> Add Connection, sau ƒë√≥ config nh∆∞ sau:
    ```bash
    Connection ID: spark_default
    Connection Type: Spark
    Host: spark-master
    Port: 7077
    ```
8. Th·ª±c hi·ªán ch·∫°y DAG ngay tr√™n Airflow Web Server

---

## üîó Giao di·ªán qu·∫£n tr·ªã

- Airflow: localhost:8082
login: airflow
pass: airflow

- pgAdmin (UI cho postgres): 
login: admin@admin.com
pass: admin
----------------------
Register servers:
hostname: postgres
username: postgres
password: postgres

- Kafka-UI (UI qu·∫£n l√≠ v√† theo d√µi c√°c brokers, topics, consumers): localhost:8080

- Spark Master (UI qu·∫£n l√≠ v√† theo d√µi tr·∫°ng th√°i c·ªßa workers): localhost:8081