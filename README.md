# OpenWeatherAPI Data Pipeline | Data Engineering Project

T·∫≠p trung v√†o vi·ªác h·ªçc c√°ch k·∫øt n·ªëi m·ªôt s·ªë c√¥ng ngh·ªá DE ph·ªï bi·∫øn ƒë·ªÉ l√†m vi·ªác v·ªõi nhau trong Docker.  
Project **kh√¥ng** t·∫≠p trung v√†o transform ph·ª©c t·∫°p hay t·ªëi ∆∞u n√¢ng cao nh∆∞ m√¥i tr∆∞·ªùng production.

---

## üìë M·ª•c l·ª•c
- [üéØ Gi·ªõi thi·ªáu](#-gi·ªõi-thi·ªáu)  
- [üß© Ki·∫øn tr√∫c h·ªá th·ªëng](#-ki·∫øn-tr√∫c-h·ªá-th·ªëng)  
- [üìà Lu·ªìng d·ªØ li·ªáu](#-lu·ªìng-d·ªØ-li·ªáu)  
- [‚öôÔ∏è H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t & ch·∫°y](#Ô∏è-h∆∞·ªõng-d·∫´n-c√†i-ƒë·∫∑t--ch·∫°y)  
- [üîó Giao di·ªán qu·∫£n tr·ªã](#-giao-di·ªán-qu·∫£n-tr·ªã)  

---

## üéØ Gi·ªõi thi·ªáu

Project n√†y ƒë√≥ng vai tr√≤ nh∆∞ m·ªôt project to√†n di·ªán ƒë·ªÉ x√¢y d·ª±ng m·ªôt pipeline d·ªØ li·ªáu end-to-end.  

Bao g·ªìm to√†n b·ªô c√°c b∆∞·ªõc t·ª´ **thu th·∫≠p d·ªØ li·ªáu th·ªùi ti·∫øt th·ª±c t·∫ø ƒë∆∞·ª£c fetching t·ª´ OpenWeather API b·ªüi Kafka**, ƒë·∫øn **x·ª≠ l√Ω d·ªØ li·ªáu v·ªõi Spark**, v√† cu·ªëi c√πng l√† **l∆∞u tr·ªØ k·∫øt qu·∫£ v√†o PostgreSQL**.  

T·∫•t c·∫£ lu·ªìng d·ªØ li·ªáu ƒë∆∞·ª£c **trigger theo l·ªãch tr√¨nh t·ª± ƒë·ªông b·ªüi Airflow** ‚Üí ƒë√¢y l√† m·ªôt b√†i to√°n **batch processing** ƒëi·ªÉn h√¨nh, n∆°i d·ªØ li·ªáu ƒë∆∞·ª£c x·ª≠ l√Ω theo t·ª´ng l√¥ ƒë·ªãnh k·ª≥ thay v√¨ realtime.

Pipeline s·ª≠ d·ª•ng m·ªôt b·ªô c√¥ng ngh·ªá hi·ªán ƒë·∫°i bao g·ªìm **Apache Airflow, Python, Apache Kafka, Apache Spark v√† PostgreSQL**.  
To√†n b·ªô h·ªá th·ªëng ƒë∆∞·ª£c **container h√≥a b·∫±ng Docker** ƒë·ªÉ gi√∫p vi·ªác tri·ªÉn khai tr·ªü n√™n d·ªÖ d√†ng, ƒë·ªìng nh·∫•t v√† c√≥ th·ªÉ m·ªü r·ªông.

---

## üß© Ki·∫øn tr√∫c h·ªá th·ªëng

![Ki·∫øn tr√∫c h·ªá th·ªëng](https://github.com/lehuy54/weather-data-pipeline/blob/main/Ki%E1%BA%BFn%20tr%C3%BAc%20h%E1%BB%87%20th%E1%BB%91ng.png)

- **Data source**: OpenWeatherAPI, l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt t·ª´ 3 th√†nh ph·ªë: H·∫£i Ph√≤ng, H√† N·ªôi, TP.HCM.  
- **Apache Airflow**: Orchestrator, ƒëi·ªÅu ph·ªëi pipeline (trigger Kafka fetch API, submit Spark job, ghi v√†o Postgres).  
- **Apache Kafka**: Message broker truy·ªÅn d·ªØ li·ªáu. S·ª≠ d·ª•ng **KRaft mode** ƒë·ªÉ t·ª± qu·∫£n l√Ω metadata, lo·∫°i b·ªè ph·ª• thu·ªôc v√†o Zookeeper.  
- **Apache Spark**: Spark Cluster x·ª≠ l√Ω d·ªØ li·ªáu ‚Üí Master node ƒëi·ªÅu ph·ªëi c√¥ng vi·ªác, Worker node x·ª≠ l√Ω v√† ghi v√†o PostgreSQL.  
- **PostgreSQL**: V·ª´a qu·∫£n l√Ω metadata c·ªßa Airflow, v·ª´a l∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω t·ª´ Spark.  

---

## üìà Lu·ªìng d·ªØ li·ªáu

1. **Airflow** trigger DAG ƒë·ªãnh k·ª≥ ‚Üí g·ªçi Python script.  
2. Script g·ªçi **OpenWeather API** ‚Üí l·∫•y d·ªØ li·ªáu 3 th√†nh ph·ªë ‚Üí g·ª≠i v√†o **Kafka topic `weather-data`**.  
3. **Spark job** (submit qua `SparkSubmitOperator`) ƒë·ªçc t·ª´ Kafka ‚Üí x·ª≠ l√Ω d·ªØ li·ªáu:  
   - Chu·∫©n h√≥a schema  
   - Ph√¢n lo·∫°i m·ª©c nhi·ªát ƒë·ªô (l·∫°nh / m√°t / n√≥ng)  
4. Spark ghi d·ªØ li·ªáu v√†o PostgreSQL b·∫£ng `weather_processed`.  
5. C√≥ th·ªÉ xem d·ªØ li·ªáu qua **pgAdmin UI** ho·∫∑c query tr·ª±c ti·∫øp.  

---

## ‚öôÔ∏è H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t & ch·∫°y

1. Clone repository:
    ```bash
    git clone https://github.com/lehuy54/weather-data-pipeline.git
    ```
2. V√†o https://openweathermap.org/api l·∫•y API KEY, sau ƒë√≥ t·∫°o file .env v√† g√°n:
    ```bash
    OPENWEATHER_API_KEY=
    ```
3. G√°n th√™m bi·∫øn sau v√†o .env
    ```bash
    AIRFLOW_UID=50000
    ```
4. M·∫∑c ƒë·ªãnh image c·ªßa apache/airflow:3.0.6 kh√¥ng bao g·ªìm Java Runtime. M√† ta l·∫°i d√πng SparkSubmitOperator ·ªü deploy mode l√† client ƒë·ªÉ submit job cho Spark Cluster (·ªü ƒë√¢y l√† t·ª´ image apache:spark), n√™n y√™u c·∫ßu Java c√≥ s·∫µn trong m√¥i tr∆∞·ªùng, ƒë·ªìng th·ªùi c√†i m·ªôt s·ªë Python package c·∫ßn thi·∫øt. Ch√≠nh v√¨ th·∫ø ta c·∫ßn ph·∫£i build l·∫°i custom Airflow image:
    ```bash
    docker compose build
    ```
5. Kh·ªüi ƒë·ªông database:
    ```bash
    docker compose up airflow-init
    ```
6. Kh·ªüi ƒë·ªông t·∫•t c·∫£ c√°c service:
    ```bash
    docker compose up -d
    ```
7. V√†o Airflow Web Server http://localhost:8082/, ƒëƒÉng nh·∫≠p v·ªõi login/password l√† airflow/airflow, sau ƒë√≥ ch·ªçn Admin -> Connections -> Add Connection, sau ƒë√≥ config nh∆∞ sau:
    ```bash
    Connection ID: spark_default
    Connection Type: Spark
    Host: spark-master
    Port: 7077
    ```
8. Th·ª±c hi·ªán ch·∫°y DAG ngay tr√™n Airflow Web Server

---

## üîó Giao di·ªán qu·∫£n tr·ªã

| Service          | URL                          | User / Login         | Password   | Ghi ch√∫                                |
|------------------|------------------------------|----------------------|------------|----------------------------------------|
| **Airflow**      | [localhost:8082](http://localhost:8082) | `airflow`           | `airflow` | ƒêi·ªÅu ph·ªëi DAGs                        |
| **pgAdmin**      | [localhost:5050](http://localhost:5050) | `admin@admin.com`   | `admin`   | UI cho PostgreSQL                      |
| PostgreSQL       | `postgres` (hostname)       | `postgres`           | `postgres` | Th√¥ng tin khi add server trong pgAdmin |
| **Kafka UI**     | [localhost:8080](http://localhost:8080) | -                    | -          | Qu·∫£n l√Ω brokers, topics, consumers     |
| **Spark Master** | [localhost:8081](http://localhost:8081) | -                    | -          | Theo d√µi tr·∫°ng th√°i cluster            |

